{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92778525",
   "metadata": {},
   "source": [
    "# Assignment 3: Non-Linear Models and Validation Metrics (37 total marks)\n",
    "### Due: October 24 at 11:59pm\n",
    "\n",
    "### Name: Ehsan Liaqat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce31b39a",
   "metadata": {},
   "source": [
    "### In this assignment, you will need to write code that uses non-linear models to perform classification and regression tasks. You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf275ca7",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2b67a661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee2d2c3",
   "metadata": {},
   "source": [
    "## Part 1: Regression (14.5 marks)\n",
    "\n",
    "For this section, we will be continuing with the concrete example from yellowbrick. You will need to compare these results to the results from the previous assignment. Please use the results from the solution if you were unable to complete Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8219f163",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (0.5 marks)\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/concrete.html\n",
    "\n",
    "Use the yellowbrick function `load_concrete()` to load the concrete dataset into the feature matrix `X` and target vector `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2af8bd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Import concrete dataset from yellowbrick library\n",
    "\n",
    "from yellowbrick.datasets import load_concrete\n",
    "X,y = load_concrete()\n",
    "#print(X)\n",
    "#print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fea4cc",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (0 marks)\n",
    "\n",
    "Data processing was completed in the previous assignment. No need to repeat here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a245d00",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import the Decision Tree, Random Forest and Gradient Boosting Machines regression models from sklearn\n",
    "2. Instantiate the three models with `max_depth = 5`. Are there any other parameters that you will need to set?\n",
    "3. Implement each machine learning model with `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c2495b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor(max_depth=5, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(max_depth=5, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingRegressor(max_depth=5, random_state=0)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "#split the data\n",
    "\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X,y, random_state=0)\n",
    "\n",
    "DT_model = DecisionTreeRegressor(random_state=0, max_depth=5)\n",
    "RF_model = RandomForestRegressor(random_state=0, max_depth=5)\n",
    "GB_model = GradientBoostingRegressor(random_state=0, max_depth=5)\n",
    "\n",
    "DT_model.fit(X_tr, y_tr)\n",
    "RF_model.fit(X_tr, y_tr)\n",
    "GB_model.fit(X_tr,y_tr)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f994e31",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model\n",
    "\n",
    "Calculate the average training and validation accuracy using mean squared error with cross-validation. To do this, you will need to set `scoring='neg_mean_squared_error'` in your `cross_validate` function and negate the results (multiply by -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "aa3e64c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Train Score MSE = 47.27976\n",
      "Decision Tree Val Score MSE = 73.44733\n",
      "RandomForest Train Score MSE = 29.57745\n",
      "RandomForest Val Score MSE = 45.05935\n",
      "GradientBoosting Train Score MSE = 3.37944\n",
      "GradientBoosting Val Score MSE = 22.78322\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "score_DT_cval = cross_validate(DT_model, X_tr, y_tr, cv=5, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "score_RF_cval = cross_validate(RF_model, X_tr, y_tr, cv=5, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "score_GB_cval = cross_validate(GB_model, X_tr, y_tr, cv=5, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "\n",
    "#print(score_DT_cval['train_score'].mean()*-1)\n",
    "#print(score_DT_cval['test_score'].mean()*-1)\n",
    "\n",
    "\n",
    "print(\"Decision Tree Train Score MSE = {:.5f}\".format(score_DT_cval['train_score'].mean()*-1))\n",
    "print(\"Decision Tree Val Score MSE = {:.5f}\".format(score_DT_cval['test_score'].mean()*-1))\n",
    "\n",
    "print(\"RandomForest Train Score MSE = {:.5f}\".format(score_RF_cval['train_score'].mean()*-1))\n",
    "print(\"RandomForest Val Score MSE = {:.5f}\".format(score_RF_cval['test_score'].mean()*-1))\n",
    "\n",
    "print(\"GradientBoosting Train Score MSE = {:.5f}\".format(score_GB_cval['train_score'].mean()*-1))\n",
    "print(\"GradientBoosting Val Score MSE = {:.5f}\".format(score_GB_cval['test_score'].mean()*-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc3f7a8",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (4 marks)\n",
    "\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy, and index: DT, RF and GB\n",
    "2. Add the accuracy results to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fdc93a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   training accuracy validation accuracy\n",
      "DT          47.27976            73.44733\n",
      "RF          29.57745            45.05935\n",
      "GB           3.37944            22.78322\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
    "\n",
    "columns_add = ['training accuracy', 'validation accuracy']\n",
    "ind_add = ['DT','RF','GB']\n",
    "model_cv = [score_DT_cval, score_RF_cval, score_GB_cval]\n",
    "\n",
    "results = pd.DataFrame(columns=columns_add, index = ind_add)\n",
    "\n",
    "for model, cv in zip(ind_add, model_cv):\n",
    "    results.loc[model] = [\"{:.5f}\".format(cv['train_score'].mean()*-1), \"{:.5f}\".format(cv['test_score'].mean()*-1)]\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31715a9d",
   "metadata": {},
   "source": [
    "Repeat the step above to print the R2 score instead of the mean-squared error. For this case, you can use `scoring='r2'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "83539f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Train Score r2 = 0.83447\n",
      "Decision Tree Val Score r2 = 0.73870\n",
      "RandomForest Train Score r2 = 0.89656\n",
      "RandomForest Val Score r2 = 0.84093\n",
      "GradientBoosting Train Score r2 = 0.98817\n",
      "GradientBoosting Val Score r2 = 0.91947\n",
      "   training accuracy validation accuracy\n",
      "DT           0.83447             0.73870\n",
      "RF           0.89656             0.84093\n",
      "GB           0.98817             0.91947\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "\n",
    "score_DT_cval = cross_validate(DT_model, X_tr, y_tr, cv=5, scoring='r2', return_train_score=True)\n",
    "score_RF_cval = cross_validate(RF_model, X_tr, y_tr, cv=5, scoring='r2', return_train_score=True)\n",
    "score_GB_cval = cross_validate(GB_model, X_tr, y_tr, cv=5, scoring='r2', return_train_score=True)\n",
    "\n",
    "#print(score_DT_cval['train_score'].mean()*-1)\n",
    "#print(score_DT_cval['test_score'].mean()*-1)\n",
    "\n",
    "\n",
    "print(\"Decision Tree Train Score r2 = {:.5f}\".format(score_DT_cval['train_score'].mean()))\n",
    "print(\"Decision Tree Val Score r2 = {:.5f}\".format(score_DT_cval['test_score'].mean()))\n",
    "\n",
    "print(\"RandomForest Train Score r2 = {:.5f}\".format(score_RF_cval['train_score'].mean()))\n",
    "print(\"RandomForest Val Score r2 = {:.5f}\".format(score_RF_cval['test_score'].mean()))\n",
    "\n",
    "print(\"GradientBoosting Train Score r2 = {:.5f}\".format(score_GB_cval['train_score'].mean()))\n",
    "print(\"GradientBoosting Val Score r2 = {:.5f}\".format(score_GB_cval['test_score'].mean()))\n",
    "\n",
    "columns_add = ['training accuracy', 'validation accuracy']\n",
    "ind_add = ['DT','RF','GB']\n",
    "model_cv = [score_DT_cval, score_RF_cval, score_GB_cval]\n",
    "\n",
    "results = pd.DataFrame(columns=columns_add, index = ind_add)\n",
    "\n",
    "for model, cv in zip(ind_add, model_cv):\n",
    "    results.loc[model] = [\"{:.5f}\".format(cv['train_score'].mean()), \"{:.5f}\".format(cv['test_score'].mean())]\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5257a98",
   "metadata": {},
   "source": [
    "### Questions (6 marks)\n",
    "1. How do these results compare to the results using a linear model in the previous assignment? Use values.\n",
    "\n",
    "1. Out of the models you tested, which model would you select for this dataset and why?\n",
    "\n",
    "1. If you wanted to increase the accuracy of the tree-based models, what would you do? Provide two suggestions.\n",
    "\n",
    "\n",
    "*ANSWER HERE*\n",
    "\n",
    "1. Compared to the linear model used in the last assignment, we see a significant improvement using Decision Tree, Random Forest and Gradient Boosting. In the linear model from last assignment, we got R2 scores of 0.61 for training and 0.62 for validation and 111 MSE for training and 95 MSE for the validation. The non linear provide much higher R2 scores for training and validation. The best R2 score for training and validation are the following, 1st GradientBoost with 0.988 for training and 0.919 for validation, 2nd RandomForest with 0.896 for training and 0.840 for validation, 3rd DecisionTree with 0.834 for training and 0.738 for validation. For MSE, 1st GradientBoost with 3.379 for training and 22.783 for validation, 2nd RandomForest with 29.577 for training and 45.059 for validation, 3rd DecisionTree with 47.279 for training and 73.447 for validation\n",
    "2. The GradientBoost with R2 scores of 0.988 for training and 0.919 for validation and MSE of 3.379 for training and 22.783 for validation is the preferred model. It has very high performance in the training and good fit, not overfitting or underfitting.\n",
    "3. We can try different depth levels to see the model performance. With more depth, we have more nodes, which will increase model accuracy as there are more parameters that are testing. Another option is to increase n_estimators to increase how many trees can be generated which can increase accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b238f4",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93097bfe",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE*\n",
    "1. I used the examples posted on the D2L to source my code.\n",
    "2. I completed my steps in sequence, one after another and followed the examples posted online.\n",
    "3. No I did not use generative AI since I didn't have time.\n",
    "4. Yes, trying understand the deeper details of how the models can increase accuracy for the same dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c6de86",
   "metadata": {},
   "source": [
    "## Part 2: Classification (17.5 marks)\n",
    "\n",
    "You have been asked to develop code that can help the user classify different wine samples. Following the machine learning workflow described in class, write the relevant code in each of the steps below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d33a8",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (2 marks)\n",
    "\n",
    "The data used for this task can be downloaded from UCI: https://archive.ics.uci.edu/dataset/109/wine\n",
    "\n",
    "Use the pandas library to load the dataset. You must define the column headers if they are not included in the dataset \n",
    "\n",
    "You will need to split the dataset into feature matrix `X` and target vector `y`. Which column represents the target vector?\n",
    "\n",
    "Print the size and type of `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "33583c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2314 (178, 13) <class 'pandas.core.frame.DataFrame'>\n",
      "178 (178,) <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Import wine dataset\n",
    "import os\n",
    "import requests\n",
    "\n",
    "def load_wine():\n",
    "\n",
    "    file_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data'\n",
    "    file_name = file_url.split('/')[-1]\n",
    "    \n",
    "    if not os.path.isfile(file_name):\n",
    "        print('Downloading from {}'.format(file_url))\n",
    "        r = requests.get(file_url)\n",
    "        with open(file_name,'wb') as output_file:\n",
    "            output_file.write(r.content)\n",
    "        \n",
    "    data = pd.read_csv(file_name, \n",
    "                   na_values='?', \n",
    "                   names=['class', 'Alcohol', 'Malicacid', 'Ash', 'Alcalinity_of_ash', 'Magnesium',\n",
    "                            'Total_phenols', 'Flavanoids', 'Nonflavanoid_phenols', 'Proanthocyanins', 'Color_intensity',\n",
    "                            'Hue', '0D280_0D315_of_diluted_wines', 'Proline'])\n",
    "    \n",
    "    return data\n",
    "\n",
    "data = load_wine()\n",
    "\n",
    "X = data.drop(columns=['class'])\n",
    "y = data['class']\n",
    "\n",
    "print(X.size, X.shape, type(X))\n",
    "print(y.size, y.shape, type(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156db208",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (1.5 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28af110",
   "metadata": {},
   "source": [
    "Print the first five rows of the dataset to inspect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ea266921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   class  Alcohol  Malicacid   Ash  Alcalinity_of_ash  Magnesium  \\\n",
      "0      1    14.23       1.71  2.43               15.6        127   \n",
      "1      1    13.20       1.78  2.14               11.2        100   \n",
      "2      1    13.16       2.36  2.67               18.6        101   \n",
      "3      1    14.37       1.95  2.50               16.8        113   \n",
      "4      1    13.24       2.59  2.87               21.0        118   \n",
      "\n",
      "   Total_phenols  Flavanoids  Nonflavanoid_phenols  Proanthocyanins  \\\n",
      "0           2.80        3.06                  0.28             2.29   \n",
      "1           2.65        2.76                  0.26             1.28   \n",
      "2           2.80        3.24                  0.30             2.81   \n",
      "3           3.85        3.49                  0.24             2.18   \n",
      "4           2.80        2.69                  0.39             1.82   \n",
      "\n",
      "   Color_intensity   Hue  0D280_0D315_of_diluted_wines  Proline  \n",
      "0             5.64  1.04                          3.92     1065  \n",
      "1             4.38  1.05                          3.40     1050  \n",
      "2             5.68  1.03                          3.17     1185  \n",
      "3             7.80  0.86                          3.45     1480  \n",
      "4             4.32  1.04                          2.93      735  \n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834fc8fe",
   "metadata": {},
   "source": [
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "97c6e9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class                           0\n",
      "Alcohol                         0\n",
      "Malicacid                       0\n",
      "Ash                             0\n",
      "Alcalinity_of_ash               0\n",
      "Magnesium                       0\n",
      "Total_phenols                   0\n",
      "Flavanoids                      0\n",
      "Nonflavanoid_phenols            0\n",
      "Proanthocyanins                 0\n",
      "Color_intensity                 0\n",
      "Hue                             0\n",
      "0D280_0D315_of_diluted_wines    0\n",
      "Proline                         0\n",
      "dtype: int64\n",
      "Total Null  0\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "print(data.isnull().sum())\n",
    "\n",
    "print(\"Total Null \", data.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070956af",
   "metadata": {},
   "source": [
    "How many samples do we have of each type of wine?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b37a6fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "2    71\n",
      "1    59\n",
      "3    48\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e6c46f",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import `SVC` and `DecisionTreeClassifier` from sklearn\n",
    "2. Instantiate models as `SVC()` and `DecisionTreeClassifier(max_depth = 3)`\n",
    "3. Implement the machine learning model with `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7528b185",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X,y, random_state=0)\n",
    "\n",
    "DTC_model = DecisionTreeClassifier(max_depth=3, random_state=0).fit(X_tr, y_tr)\n",
    "SVC_model = SVC(random_state=0).fit(X_tr, y_tr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0870b0d2",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model \n",
    "\n",
    "Calculate the average training and validation accuracy using `cross_validate` for the two different models listed in Step 3. For this case, use `scoring='accuracy'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ae738294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier Train Score Accuracy = 0.99436\n",
      "DecisionTreeClassifier Val Score Accuracy = 0.89402\n",
      "SVC Train Score Accuracy = 0.68043\n",
      "SVC Val Score Accuracy = 0.67664\n"
     ]
    }
   ],
   "source": [
    "score_DTC_cval = cross_validate(DTC_model, X_tr, y_tr, cv=5, scoring='accuracy', return_train_score=True)\n",
    "score_SVC_cval = cross_validate(SVC_model, X_tr, y_tr, cv=5, scoring='accuracy', return_train_score=True)\n",
    "\n",
    "#print(score_DT_cval['train_score'].mean()*-1)\n",
    "#print(score_DT_cval['test_score'].mean()*-1)\n",
    "\n",
    "print(\"DecisionTreeClassifier Train Score Accuracy = {:.5f}\".format(score_DTC_cval['train_score'].mean()))\n",
    "print(\"DecisionTreeClassifier Val Score Accuracy = {:.5f}\".format(score_DTC_cval['test_score'].mean()))\n",
    "\n",
    "\n",
    "print(\"SVC Train Score Accuracy = {:.5f}\".format(score_SVC_cval['train_score'].mean()))\n",
    "print(\"SVC Val Score Accuracy = {:.5f}\".format(score_SVC_cval['test_score'].mean()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0bbd83",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (4 marks)\n",
    "\n",
    "#### Step 5.1: Compare Models\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy\n",
    "2. Add the data size, training and validation accuracy for each dataset to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "be4b5c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     data size training accuracy validation accuracy\n",
      "DTC  (133, 13)           0.99436             0.89402\n",
      "SVC  (133, 13)           0.68043             0.67664\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
    "\n",
    "columns_add = ['data size', 'training accuracy', 'validation accuracy']\n",
    "ind_add = ['DTC','SVC']\n",
    "model_cv = [score_DTC_cval, score_SVC_cval]\n",
    "\n",
    "results = pd.DataFrame(columns=columns_add, index = ind_add)\n",
    "\n",
    "for model, cv in zip(ind_add, model_cv):\n",
    "    results.loc[model] = [X_tr.shape, \"{:.5f}\".format(cv['train_score'].mean()), \"{:.5f}\".format(cv['test_score'].mean())]\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e17878",
   "metadata": {},
   "source": [
    "#### Step 5.2: Visualize Classification Errors\n",
    "Which method gave the highest accuracy? Use this method to print the confusion matrix and classification report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "44b091a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14  2  0]\n",
      " [ 0 20  1]\n",
      " [ 0  0  8]]\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Implement best model\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "mat = confusion_matrix(y_val, DTC_model.predict(X_val))\n",
    "print(mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "09d21b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(170.97222222222223, 0.5, 'true value')"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TO DO: Print confusion matrix using a heatmap\n",
    "\n",
    "\n",
    "sns.heatmap(mat, xticklabels=[1,2,3], yticklabels=[1,2,3], square=True, annot=True, cbar=False)\n",
    "plt.xlabel('predicted value')\n",
    "plt.ylabel('true value')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5ef95947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.88      0.93        16\n",
      "           2       0.91      0.95      0.93        21\n",
      "           3       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.93        45\n",
      "   macro avg       0.93      0.94      0.93        45\n",
      "weighted avg       0.94      0.93      0.93        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Print classification report\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_val,DTC_model.predict(X_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf319621",
   "metadata": {},
   "source": [
    "### Questions (6 marks)\n",
    "1. How do the training and validation accuracy change depending on the method used? Explain with values.\n",
    "1. What are two reasons why the support vector machines model did not work as well as the tree-based model?\n",
    "1. How many samples were incorrectly classified in step 5.2? \n",
    "1. In this case, is maximizing precision or recall more important? Why?\n",
    "\n",
    "*YOUR ANSWERS HERE*\n",
    "\n",
    "1. The DecisionTreeClassifier gave much higher accuracy. The acurracy results for DecisionTreeClassifier are 0.994 for traning and 0.894 for validation. For SVC the accuracy results are 0.680 for training and 0.676 for validation. See how DecisionTreeClassifier is a better fit, it would be the better model.\n",
    "\n",
    "2. The SVC model is very responsive to data scaling, as we can see the data has float values as low as 0.01 to over 1000, which are widely apart. This may cause poor performance of the SVM mode. Another issue is adjustmnent of tuning parameters so the SVC model can perform better was not carried out. If we can fine tune the parameters of the SVC model we might be able to see an improvement.\n",
    "\n",
    "3. 3 samples\n",
    "\n",
    "4. Recall means capturing as many positive IDs as possible. With increasing recall, precision will go down. That suggests that model becomes less accurate. In this case, with three types of wine, we need to maximize precision and improve accuracy, because an accurate model will increase ID of wine. Here having false positive will be harmful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664ff8ae",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?\n",
    "\n",
    "1. I used the posted examples on D2L\n",
    "2. In sequence, steps 1 - 5\n",
    "3. Yes a little to understand why SVC can perform poorly. I asked \"What causes SVM to perform worse than DecisionTreeClassifier and explain it\". I did not modify the code.\n",
    "4. Yes I had some issues running the code. Also issues with things not being defined. I fixed them by investigating them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e837da",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd7358d",
   "metadata": {},
   "source": [
    "## Part 3: Observations/Interpretation (3 marks)\n",
    "\n",
    "Describe any pattern you see in the results. Relate your findings to what we discussed during lectures. Include data to justify your findings.\n",
    "\n",
    "With equal depth levels, we can compare the performane of different non linear models. Using the max depth of 5, the GradientBoost model was the best performer with the similar tree depth. The training score was 0.988 and validation score was 0.919. The GradientBoost model can achieve higher performance by developing multiple trees iteratively. The RandomForest came in second with training score of 0.896 and validation score of 0.840. It is an ensemble of decision tree and improves upon decision tree using multiple trees with different features which increase accuracy. Decision tree has the lowest performance but better than the linear model. It has a training accuracy of 0.834 and validation accuracy of 0.738. Both RandomForest and GradientBoost are improved version of the DecisionTree, which is seen in the accuracy results. The second part demonstrates that without fine tuning parameters, or choosing a non suitable model for data, where scaling is high, you can run into many performance issues. As seen in the SVC model, the performance is significantly worse than the DecisionTreeClassifier model.\n",
    "\n",
    "\n",
    "*ADD YOUR FINDINGS HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd97b6ac",
   "metadata": {},
   "source": [
    "## Part 4: Reflection (2 marks)\n",
    "Include a sentence or two about:\n",
    "- what you liked or disliked,\n",
    "- found interesting, confusing, challangeing, motivating\n",
    "while working on this assignment.\n",
    "\n",
    "\n",
    "*ADD YOUR THOUGHTS HERE*\n",
    "\n",
    "- I liked the layout and user friendliness of the assignment. I like the format as it follows assignnment 2\n",
    "- The concepts are still very challenging to understand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa21e53b",
   "metadata": {},
   "source": [
    "## Part 5: Bonus Question (3 marks)\n",
    "\n",
    "Repeat Part 2 and compare the support vector machines model used to `LinearSVC(max_iter=5000)`. Does using `LinearSVC` improve the results? Why or why not?\n",
    "\n",
    "Is `LinearSVC` a good fit for this dataset? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "30fea72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\.conda\\envs\\ensf-ml\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Asus\\.conda\\envs\\ensf-ml\\Lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Asus\\.conda\\envs\\ensf-ml\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Asus\\.conda\\envs\\ensf-ml\\Lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Asus\\.conda\\envs\\ensf-ml\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Asus\\.conda\\envs\\ensf-ml\\Lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Asus\\.conda\\envs\\ensf-ml\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Asus\\.conda\\envs\\ensf-ml\\Lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Asus\\.conda\\envs\\ensf-ml\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Asus\\.conda\\envs\\ensf-ml\\Lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Asus\\.conda\\envs\\ensf-ml\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Train Score Accuracy = 0.86829\n",
      "SVM Val Score Accuracy = 0.84986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\.conda\\envs\\ensf-ml\\Lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "\n",
    "X_tr2 = X_tr\n",
    "y_tr2 = y_tr\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "linear_svm = LinearSVC(max_iter=5000, random_state=0).fit(X_tr2, y_tr2)\n",
    "\n",
    "score_SVM_cval= cross_validate(linear_svm, X_tr2, y_tr2, cv=5, scoring='accuracy', return_train_score=True)\n",
    "\n",
    "print(\"SVM Train Score Accuracy = {:.5f}\".format(score_SVM_cval['train_score'].mean()))\n",
    "print(\"SVM Val Score Accuracy = {:.5f}\".format(score_SVM_cval['test_score'].mean()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabc68a4",
   "metadata": {},
   "source": [
    "*ANSWER HERE*\n",
    "\n",
    "The LinearSVC model seems to perform better than the SVC model, with training accuracy of 0.868 and validation accuracy 0.849. Compared to SVC, it is much better. Perhaps for the data, going with with a linear based model is better suited."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('ensf-ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "5a29cbdb3a4d87bd4ca51dbe633eced75e23fbf7317d5f915665cf29f889d0cd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
